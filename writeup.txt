ShopGenie is a multi-agent retail assistant that connects language models to backend systems for a simple shopping experience. Customers experience quick answers, recommendations, and order placements. Traditional rule-based chatbots often miss context and it is a complex task when involving backend tasks; ShopGenie shows a practical way to combine natural language with real system interactions.

Core features: natural-language product discovery, order lifecycle management (place, list, return), and multi-agent reasoning with controlled tool usage. The architecture is modular: new agents such as a Payment Agent or Inventory Agent can be added without changing the Orchestrator. Tool calls are validated and agent roles are isolated to ensure reliability.

Architecture: The system uses three agents with clear roles: Service Agent, Product Agent, and Orchestrator. The Service Agent handles user intent such as support requests, order inquiries, returns, and FAQs. The Product Agent performs semantic product search and applies filters like budget, brand, and category. The Orchestrator receives frontend input, chooses the right agent, manages tool calls, validates outputs, and composes the final reply. This sort of workflow is to ensure that these agents keeps behavior  predictable and the risk of errors in tasks due to multiple agents involved, reduces. The whole solution is hosted on Cloud Run, Google Cloud Platform, deployed via CLI.

The entire development of ShopGenie was streamlined by leveraging Google ADK (Agent Development Kit), which acted as the core environment for building, testing, and iterating on the multi-agent system. ADK’s integrated workflows made it possible to rapidly prototype agent behaviors, validate tool schemas, and debug incorrect or malformed LLM outputs without leaving the platform. Features like built-in tool execution wrappers, automatic JSON validation, and structured prompt templates significantly reduced the issues commonly encountered in LLM-driven applications, such as hallucinated fields, unsafe SQL queries, and mismatches between agent outputs. ADK’s session-based runtime also helped isolate agent state cleanly, preventing cross-contamination of memory between different user flows. Additionally, ADK’s serverless execution model simplified backend integration by allowing Python tools, SQL clients, and orchestrator logic to run in a unified environment without manual dependency management. The modular agent configuration system in ADK made it easy to plug in new agents, update behaviors, and enforce strict interfaces, which directly supported ShopGenie's design and controlled tool usage. Overall, Google ADK removed much of the core issues, allowing development to focus on correctness, safety, and user experience rather than debugging environment issues or wiring components manually.

The user interface for ShopGenie is built using Streamlit, providing a clean, responsive, and conversational front-end for interacting with the multi-agent system. Customers simply enter their user ID and type a natural-language query, after which the Orchestrator processes the request, triggers the appropriate agent calls, and composes a unified response. One of the features in this project is its built-in session state management where it preserves user context across interactions without requiring additional logic or backend state tracking. This ensures that multi-step conversations, such as browsing items, selecting a product, and placing an order, flow smoothly without losing intermediate results. The interface is tightly integrated with a persistent SQLite database, where all product information, order records, and return requests are stored. Because the database is written to a file and maintained across sessions, actions like placing an order, listing past purchases, or initiating a return are reliably saved and remain available even after restarting the app. Overall, Streamlit provides an intuitive and stable environment that bridges the frontend with the multi-agent backend, making ShopGenie interactive and stateful.

The SQLite backend serves as the information source for the entire system, storing all products, orders, returns, timestamps, and user identifiers in a structured format. Instead of allowing agents to execute SQL statements directly, which could lead to hallucinations, malformed queries, or even data corruption, the system relies on tightly controlled Python tool wrappers. Each tool exposes only a narrowly defined operation such as list_orders, search_products, or place_order, and all arguments passed to these tools are validated for type, schema, and allowed values before execution. This prevents agents from inventing product IDs, altering fields that should remain immutable, or querying nonexistent columns. Importantly, because these tools abstract raw SQL, the database remains protected from injection-like behavior even when the LLM generates imperfect outputs. This design ensures data integrity, reduces the risk of failures during live interactions, and keeps the entire pipeline safe, consistent, and reliable.

Sample User flow: a user asks for "shoes under 3000." The Orchestrator routes the request to the Product Agent, which queries the database and returns results. If the user then says "Place an order for the second one," the Orchestrator extracts and validates the product ID, calls the place_order tool, inserts a row into orders, and returns a confirmation. Similar flows cover listing past orders and initiating returns.

Challenges tackled: Several challenges emerged while building ShopGenie, particularly due to the unpredictable nature of LLM-generated JSON and the tendency of models to hallucinate missing fields. Early prototypes frequently produced malformed tool calls or added imaginary attributes, which caused runtime errors and inconsistent behavior. To address this, strict schema validation was introduced along with error-correcting middleware that automatically fixes minor JSON deviations, rewrites agent outputs to match required formats, or rejects unsafe requests. Another challenge arose from Streamlit’s execution model. Because Streamlit re-runs the script on every user interaction, it caused duplicate agent initialization, repeated database connections, and inconsistent session states. This was solved using Streamlit’s cached singleton pattern, ensuring that the multi-agent framework, SQL client, and configuration were created only once per session. Together, these solutions made the system far more stable and eliminated the most common failure modes seen in LLM-powered apps.

Future roadmap: add voice input, use vector embeddings for semantic search, integrate payment providers through means like Stripe, and deploy asan API-backed service with caching and load balancing.
